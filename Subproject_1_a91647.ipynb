{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504d408a",
   "metadata": {
    "id": "504d408a"
   },
   "source": [
    "# Subproject 1 – Used Car Prices Prediction\n",
    "Machine Learning – M.Sc. in Electrical and Computer Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9be13e",
   "metadata": {
    "id": "0d9be13e"
   },
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b568a7",
   "metadata": {
    "id": "a0b568a7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf95a5",
   "metadata": {
    "id": "06cf95a5"
   },
   "source": [
    "Reading datasets files and making dataframes using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168fa99",
   "metadata": {
    "collapsed": true,
    "id": "e168fa99"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bQWwe-0pRESp",
   "metadata": {
    "id": "bQWwe-0pRESp"
   },
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "After reading and making DataFrames of the Datasets, i will be analysing the data.\n",
    "\n",
    "Purpose: \n",
    "\n",
    "This will let me understand the kind of datatype i am working. \n",
    "It will let me understand the kind of features that are present in the Data, if they are categorical or numerical features.\n",
    "If there there are missing values in the data, and the type (if any). This make me have better decision on methods i can use to fill up the values.\n",
    "\n",
    "To do this i will be making use of some methods from the pandas library such as \"shape()\", \"head()\", \"info()\", \"dtypes()\", \"describe()\". \n",
    "\n",
    "During this EDA, i wil also be exploring some other related and important part which wich will let me make better decision when training tdata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GF_SWkO0gLI8",
   "metadata": {
    "id": "GF_SWkO0gLI8"
   },
   "source": [
    "using the shape() method, will give the dimension (row x columns) of the data i am working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GNb6qxxeTLYv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "GNb6qxxeTLYv",
    "outputId": "ffd76408-f25e-49bc-b0b9-320a3cc9c81c"
   },
   "outputs": [],
   "source": [
    "# for train data\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oBX72suhgRDj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "oBX72suhgRDj",
    "outputId": "d58052af-ba98-48cb-bea1-803bf6768c01"
   },
   "outputs": [],
   "source": [
    "# for test data\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gsh6tq13eFHX",
   "metadata": {
    "id": "Gsh6tq13eFHX"
   },
   "source": [
    "the head() method will show first rows of data but limited, \"n\" can be passed as an argument, if we want specific amount of row to be shown.\n",
    "\n",
    "passing n as an argument here will show the first n rows from index (0 to n-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JpdNp4RITee3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "JpdNp4RITee3",
    "outputId": "48a83bc2-fd2f-4bbb-afbe-20d7c374a7e5"
   },
   "outputs": [],
   "source": [
    "# for train data\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeZWj74reXA7",
   "metadata": {
    "id": "aeZWj74reXA7"
   },
   "outputs": [],
   "source": [
    "# for test data\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdbea8",
   "metadata": {
    "id": "46bdbea8"
   },
   "source": [
    "Using info() method to see the summary details about the dataframes like the index, datatypes, columns, non-null values and the memory usage.\n",
    "\n",
    "Ths method also shows the total numbers of values for each of the columns present in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e00ebf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "36e00ebf",
    "outputId": "cb5e0ef3-0ca2-450d-f586-f02e0f6c1958"
   },
   "outputs": [],
   "source": [
    "#  for the train data\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P5WljiTidc41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "P5WljiTidc41",
    "outputId": "2afba4ef-c170-490e-82ea-e065319e3b28"
   },
   "outputs": [],
   "source": [
    "#  for the test data\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c28e9c",
   "metadata": {},
   "source": [
    "Target visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the price distribution plot below, it is noticed that the target ['price'] of the train data is skewed with fewer high-priced car.\n",
    "\n",
    "# The target distribution was analyzed to identify skewness and outliers in used car prices, which directly affects model choice and potential target transformations.\n",
    "\n",
    "# Due to the skewness from the target, we can make use of log transform, beacuse it compreses the high-price tail and also affect the proportionality of the errors.\n",
    "\n",
    "# price distrubution  visualization\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df_train[\"price\"])\n",
    "plt.title(\"Distribution of Car Prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U6gWPXDZXCEK",
   "metadata": {
    "id": "U6gWPXDZXCEK"
   },
   "source": [
    "separating numerical column and categorical column:\n",
    "\n",
    "this part shows the numerical columns and categorical features columns we have. Doing this made me understand the if there will be need for data encoding or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mxNAKIhCW_82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxNAKIhCW_82",
    "outputId": "24bb805b-0b9c-4e3d-c269-051ea22aa2ea"
   },
   "outputs": [],
   "source": [
    "#  for train data\n",
    "\n",
    "numerical_columns = df_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_columns = df_test.select_dtypes(include=[\"object\", \"bool\", \"category\"]).columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXcH7MzsiR5z",
   "metadata": {
    "id": "cXcH7MzsiR5z"
   },
   "source": [
    "Missing values\n",
    "\n",
    "the pandas library provides isnull() to check the column with missing values, sum() will give the total sum of the missing values if any exist,  and the sort_values() for sorting either in ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1QV6bKFXidYL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "id": "1QV6bKFXidYL",
    "outputId": "081f9fee-4f40-44d1-bd5e-c8a05d78b599"
   },
   "outputs": [],
   "source": [
    "# from pandas dataframe, we can use the .mean() method to find the mean for the each colums with missing values, then convert it to percentage multiplying be 100.\n",
    "\n",
    "#  Missing value analysis was performed to quantify data incompleteness and justify the imputation strategies applied during preprocessing.\n",
    "\n",
    "#  for train data\n",
    "train_missing_values =df_train.isnull().sum().sort_values(ascending=False)\n",
    "train_missing_columns = df_train.columns[df_train.isna().any()].tolist()\n",
    "\n",
    "train_missing_percentage = df_train.isnull().mean().sort_values(ascending=False) * 100\n",
    "\n",
    "train_missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htMglwcbiqbp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "id": "htMglwcbiqbp",
    "outputId": "a5836513-ced2-46c8-e146-a678e94c9564"
   },
   "outputs": [],
   "source": [
    "#for test data\n",
    "\n",
    "df_test.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "train_missing_percentage[train_missing_percentage > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot for columns with missing data\n",
    "(df_train.drop(['price'], axis=1).isnull().mean() * 100).plot(kind=\"bar\")\n",
    "plt.title(\"Missing values\")\n",
    "plt.ylabel(\"missing\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f837fd9",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc944a",
   "metadata": {},
   "source": [
    "## Filling missing data\n",
    "\n",
    "From using info() method when doing EDA above on the train data, It was seen that there are some missing values. Like in the fuel_type, accident and the clean_title features.\n",
    "\n",
    "This missing values are categorical features, therefore there is need to fill the the missing values before training because model can not be trained without with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For replacing the missing values in the training set, i used the mode() function from pandas to get the mode and using fillna() function from pandas library  to fill the positions where there was a misiing values.\n",
    "\n",
    "for column in train_missing_columns:\n",
    "    #  calculates the mode of the values.\n",
    "    replace_value = df_train[column].mode()[0]\n",
    "\n",
    "    # then filled it to the missing values position.\n",
    "    df_train[column] = df_train[column].fillna(replace_value)\n",
    "\n",
    "# For the test set, i filled only missing values for columns that are present in the train data set and excluding 'price'.\n",
    "# Doing this bring cosistency and more accuracy when training. As we are dealing with unseen data, we can't be sure if the unseen data will have additional column or not, or if they will contain some missing data, so it is best to take care of that. \n",
    " \n",
    "#  this line will select only the column with missing data in test data that are also present in the train data \n",
    "missing_columns_test = [col for col in train_missing_columns if col in df_test.columns]\n",
    "\n",
    "for column in missing_columns_test:\n",
    "    # Use the mode calculated from the training set for consistency\n",
    "    replace_value = df_train[column].mode()[0]\n",
    "    df_test[column] = df_test[column].fillna(replace_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87116650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming if the missing data was successfully filled\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27103b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230c025",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "\n",
    "it was seen from previous that there are some categorical features present in our datasets, there these categorical need to be encoded to be numerical features.\n",
    "\n",
    "To do this, i used the get_dummies() method that implements OneHotEncoding of categorical data from the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb505fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = pd.get_dummies(df_train, drop_first=True)\n",
    "\n",
    "df_test_encoded = pd.get_dummies(df_test, drop_first=True)\n",
    "df_test_encoded = df_test_encoded.reindex(columns=df_train_encoded.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.drop(['price'], axis=1).plot(kind='box', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eec337",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "After I analyzed the Data, filled the columns with missing values and encoded the categorical features. Then i moved to training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784ff00",
   "metadata": {},
   "source": [
    "First aseline models without tuning or normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4a8df",
   "metadata": {},
   "source": [
    "Created 2 functions\n",
    "\n",
    "a. getXy : split the data to features and target\n",
    "b. run_base_models: it will run base models inside it, plot and give the score for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(df):\n",
    "    X = df.drop(['price'], axis=1)\n",
    "    y = df['price']\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def run_base_models(df):\n",
    "    X,y = getXy(df)\n",
    "    # split the Dataframe\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=42, shuffle=False) \n",
    "\n",
    "    #  basemodels to use\n",
    "    base_models = {\n",
    "    \"Linear regression\": LinearRegression(),\n",
    "    \"Decision tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=10),\n",
    "    \"k-NN\": KNeighborsRegressor(n_neighbors=3)\n",
    "    }\n",
    "    \n",
    "    fig,ax = plt.subplots(len(base_models),1, figsize=(20,10))\n",
    "    base_model_scores ={}\n",
    "\n",
    "    for idx, (name, model) in enumerate(base_models.items()):\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        # i used numpy to compute each model rmse value\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "        \n",
    "        print(f'{name}: score = {score}')\n",
    "\n",
    "         # plot pred vs actual\n",
    "        ax[idx].plot(y_test.values, pred, c='g', marker='o', linestyle='None')\n",
    "        ax[idx].plot(y_test.values, y_test.values, c='r')\n",
    "        ax[idx].set_ylabel('Predicted')\n",
    "        ax[idx].set_xlabel('Actual')\n",
    "        ax[idx].set_title(f'{name} / Score =  {score}/ RMSE = {rmse}')   \n",
    "        \n",
    "        base_model_scores[name] = score\n",
    "        base_model_scores[name] = rmse\n",
    "\n",
    "    return base_model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef569546",
   "metadata": {},
   "source": [
    "Runs the baseline models and plots predicted vs actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores = pd.DataFrame()\n",
    "models_scores['Base Models'] = run_base_models(df_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7528f9c",
   "metadata": {},
   "source": [
    "Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081339a",
   "metadata": {},
   "source": [
    "Scales features, log-transforms the target, builds polynomial features, and prepares test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = getXy(df_train_encoded)\n",
    "\n",
    "standard_Scaler = StandardScaler().fit(X)\n",
    "\n",
    "df_train_scaled = pd.DataFrame(standard_Scaler.transform(X), columns = X.columns)\n",
    "df_test_scaled = standard_Scaler.transform(df_test_encoded)\n",
    "\n",
    "# df_train_scaled['']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53733fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = df_train_scaled.drop(['price'], axis=1)\n",
    "y_scaled = df_train_scaled['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151aea8",
   "metadata": {},
   "source": [
    "Models Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481567b",
   "metadata": {},
   "source": [
    "Defines grid search helper with CV RMSE and predicted vs actual plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677963d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "models = {\n",
    "    \"linreg\": (LinearRegression(), {\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"positive\": [False, True]\n",
    "    }),\n",
    "\n",
    "    \"knn\": (KNeighborsRegressor(), {\n",
    "        \"n_neighbors\": [3, 5, 7],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"minkowski\"],\n",
    "        \"p\": [1, 2]\n",
    "    }),\n",
    "\n",
    "    \"dt\": (DecisionTreeRegressor(), {\n",
    "        \"max_depth\": [None, 5, 10],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"ccp_alpha\": [0.0, 0.001, 0.01]\n",
    "    }),\n",
    "\n",
    "    \"rf\": (RandomForestRegressor(), {\n",
    "        \"n_estimators\": [100, 300],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [5, 10],\n",
    "        \"min_samples_leaf\": [1, 2],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "        \"bootstrap\": [True, False]\n",
    "    }),\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for name, (model, grid) in models.items():\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model, \n",
    "        param_grid=grid, cv=cv,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    results.append({\"model\": name, \"rmse\": -gs.best_score_, \"params\": gs.best_params_})\n",
    "    best_models[name] = gs.best_estimator_\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"rmse\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed5420",
   "metadata": {},
   "source": [
    "Builds and displays the sorted grid-search results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"rmse\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c45e87",
   "metadata": {},
   "source": [
    "Kaggle Submission File Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2a896",
   "metadata": {},
   "source": [
    "Generates submission predictions from the best model and saves submission.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406eb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the best model\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "\n",
    "# Retrieve the best estimator (pipeline) for that model\n",
    "best = best_models[best_model_name]\n",
    "\n",
    "# Preprocess the test set using the same preprocessor fitted on the training data\n",
    "# Note: The preprocess object is already part of the best_pipeline\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best.predict(df_test)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({'id': df_test['id'], 'price': predictions})\n",
    "\n",
    "# Ensure prices are non-negative, as car prices cannot be negative\n",
    "submission_df['price'] = submission_df['price'].apply(lambda x: max(0, x))\n",
    "\n",
    "# Display the first few rows of the submission file\n",
    "display(submission_df.head())\n",
    "\n",
    "# Save to CSV for Kaggle submission\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
